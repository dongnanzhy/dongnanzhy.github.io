<!DOCTYPE html>
<html>
  <head><meta name="generator" content="Hexo 3.8.0">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
  <meta name="description" content="Yan&#39;s git io">
  <meta name="keyword" content="YAN&#39;s BLOG">
  
    <link rel="shortcut icon" href="/css/images/logo.png">
  
  <title>
    
      dcgan | YAN&#39;s BLOG
    
  </title>
  <link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
  <link href="//cdn.bootcss.com/nprogress/0.2.0/nprogress.min.css" rel="stylesheet">
  <link href="//cdn.bootcss.com/highlight.js/9.12.0/styles/tomorrow.min.css" rel="stylesheet">
  <link rel="stylesheet" href="/css/style.css">
<link rel="stylesheet" href="/css/plugins/gitment.css">
  <script src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
  <script src="//cdn.bootcss.com/geopattern/1.2.3/js/geopattern.min.js"></script>
  <script src="//cdn.bootcss.com/nprogress/0.2.0/nprogress.min.js"></script>
  <script src="/js/qrious.js"></script>
<script src="/js/gitment.js"></script>
  
  
    <!-- MathJax support START -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <!-- MathJax support END -->
  


</head>
<div class="wechat-share">
  <img src="/css/images/logo.png">
</div>

  <body>
    <header class="header fixed-header">
  <div class="header-container">
    <a class="home-link" href="/">
      <div class="logo"></div>
      <span>YAN's BLOG</span>
    </a>
    <ul class="right-list">
      
        <li class="list-item">
          
            <a href="/" class="item-link">Home</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/tags/" class="item-link">Tags</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/archives/" class="item-link">Archives</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/project/" class="item-link">Projects</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/about/" class="item-link">About</a>
          
        </li>
      
    </ul>
    <div class="menu">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </div>
    <div class="menu-mask">
      <ul class="menu-list">
        
          <li class="menu-item">
            
              <a href="/" class="menu-link">Home</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/tags/" class="menu-link">Tags</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/archives/" class="menu-link">Archives</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/project/" class="menu-link">Projects</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/about/" class="menu-link">About</a>
            
          </li>
        
      </ul>
    </div>
  </div>
</header>

    <div id="article-banner">
  <h2>dcgan</h2>
  <p class="post-date">2019-01-06</p>
  <div class="arrow-down">
    <a href="javascript:;"></a>
  </div>
</div>
<main class="app-body flex-box">
  <!-- Article START -->
  <article class="post-article">
    <section class="markdown-content"><h5 id="Copyright-2018-The-TensorFlow-Authors"><a href="#Copyright-2018-The-TensorFlow-Authors" class="headerlink" title="Copyright 2018 The TensorFlow Authors."></a>Copyright 2018 The TensorFlow Authors.</h5><p>Licensed under the Apache License, Version 2.0 (the â€œLicenseâ€).</p>
<h1 id="DCGAN-An-example-with-tf-keras-and-eager"><a href="#DCGAN-An-example-with-tf-keras-and-eager" class="headerlink" title="DCGAN: An example with tf.keras and eager"></a>DCGAN: An example with tf.keras and eager</h1><table class="tfo-notebook-buttons" align="left"><td><br><a target="_blank" href="https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/generative_examples/dcgan.ipynb"><br>    <img src="https://www.tensorflow.org/images/colab_logo_32px.png">Run in Google Colab</a><br></td><td><br><a target="_blank" href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/generative_examples/dcgan.ipynb"><img width="32px" src="https://www.tensorflow.org/images/GitHub-Mark-32px.png">View source on GitHub</a></td></table>

<p>This notebook demonstrates how to generate images of handwritten digits using <a href="https://www.tensorflow.org/programmers_guide/keras" target="_blank" rel="noopener">tf.keras</a> and <a href="https://www.tensorflow.org/programmers_guide/eager" target="_blank" rel="noopener">eager execution</a>. To do so, we use Deep Convolutional Generative Adverserial Networks (<a href="https://arxiv.org/pdf/1511.06434.pdf" target="_blank" rel="noopener">DCGAN</a>).</p>
<p>This model takes about ~30 seconds per epoch (using tf.contrib.eager.defun to create graph functions) to train on a single Tesla K80 on Colab, as of July 2018.</p>
<p>Below is the output generated after training the generator and discriminator models for 150 epochs.</p>
<p><img src="https://tensorflow.org/images/gan/dcgan.gif" alt="sample output"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># to generate gifs</span></span><br><span class="line">!pip install imageio</span><br></pre></td></tr></table></figure>
<pre><code>Requirement already satisfied: imageio in /home/dongnanzhy/miniconda3/lib/python3.6/site-packages (2.1.2)
Requirement already satisfied: numpy in /home/dongnanzhy/miniconda3/lib/python3.6/site-packages (from imageio) (1.14.2)
Requirement already satisfied: pillow in /home/dongnanzhy/miniconda3/lib/python3.6/site-packages (from imageio) (5.0.0)
[33mYou are using pip version 18.0, however version 18.1 is available.
You should consider upgrading via the &apos;pip install --upgrade pip&apos; command.[0m
</code></pre><h2 id="Import-TensorFlow-and-enable-eager-execution"><a href="#Import-TensorFlow-and-enable-eager-execution" class="headerlink" title="Import TensorFlow and enable eager execution"></a>Import TensorFlow and enable eager execution</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import, division, print_function</span><br><span class="line"></span><br><span class="line"><span class="comment"># Import TensorFlow &gt;= 1.10 and enable eager execution</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">tf.enable_eager_execution()</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> PIL</span><br><span class="line"><span class="keyword">import</span> imageio</span><br><span class="line"><span class="keyword">from</span> IPython <span class="keyword">import</span> display</span><br></pre></td></tr></table></figure>
<pre><code>/home/dongnanzhy/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
</code></pre><h2 id="Load-the-dataset"><a href="#Load-the-dataset" class="headerlink" title="Load the dataset"></a>Load the dataset</h2><p>We are going to use the MNIST dataset to train the generator and the discriminator. The generator will then generate handwritten digits.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train_images = train_images.reshape(train_images.shape[<span class="number">0</span>], <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>).astype(<span class="string">'float32'</span>)</span><br><span class="line"><span class="comment"># We are normalizing the images to the range of [-1, 1]</span></span><br><span class="line">train_images = (train_images - <span class="number">127.5</span>) / <span class="number">127.5</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">BUFFER_SIZE = <span class="number">60000</span></span><br><span class="line">BATCH_SIZE = <span class="number">256</span></span><br></pre></td></tr></table></figure>
<h2 id="Use-tf-data-to-create-batches-and-shuffle-the-dataset"><a href="#Use-tf-data-to-create-batches-and-shuffle-the-dataset" class="headerlink" title="Use tf.data to create batches and shuffle the dataset"></a>Use tf.data to create batches and shuffle the dataset</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)</span><br></pre></td></tr></table></figure>
<h2 id="Write-the-generator-and-discriminator-models"><a href="#Write-the-generator-and-discriminator-models" class="headerlink" title="Write the generator and discriminator models"></a>Write the generator and discriminator models</h2><ul>
<li><p><strong>Generator</strong> </p>
<ul>
<li>It is responsible for <strong>creating convincing images that are good enough to fool the discriminator</strong>.</li>
<li>It consists of Conv2DTranspose (Upsampling) layers. We start with a fully connected layer and upsample the image 2 times so as to reach the desired image size (mnist image size) which is (28, 28, 1). </li>
<li>We use <strong>leaky relu</strong> activation except for the <strong>last layer</strong> which uses <strong>tanh</strong> activation.<br>(è¿™é‡Œä»£ç ç”¨çš„æ˜¯reluè€Œä¸æ˜¯leaky relu)</li>
</ul>
</li>
<li><p><strong>Discriminator</strong></p>
<ul>
<li><strong>The discriminator is responsible for classifying the fake images from the real images.</strong></li>
<li>In other words, the discriminator is given generated images (from the generator) and the real MNIST images. The job of the discriminator is to classify these images into fake (generated) and real (MNIST images).</li>
<li><strong>Basically the generator should be good enough to fool the discriminator that the generated images are real</strong>.</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Generator</span><span class="params">(tf.keras.Model)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">    super(Generator, self).__init__()</span><br><span class="line">    self.fc1 = tf.keras.layers.Dense(<span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>, use_bias=<span class="keyword">False</span>)</span><br><span class="line">    self.batchnorm1 = tf.keras.layers.BatchNormalization()</span><br><span class="line">    </span><br><span class="line">    self.conv1 = tf.keras.layers.Conv2DTranspose(<span class="number">64</span>, (<span class="number">5</span>, <span class="number">5</span>), strides=(<span class="number">1</span>, <span class="number">1</span>), padding=<span class="string">'same'</span>, use_bias=<span class="keyword">False</span>)</span><br><span class="line">    self.batchnorm2 = tf.keras.layers.BatchNormalization()</span><br><span class="line">    </span><br><span class="line">    self.conv2 = tf.keras.layers.Conv2DTranspose(<span class="number">32</span>, (<span class="number">5</span>, <span class="number">5</span>), strides=(<span class="number">2</span>, <span class="number">2</span>), padding=<span class="string">'same'</span>, use_bias=<span class="keyword">False</span>)</span><br><span class="line">    self.batchnorm3 = tf.keras.layers.BatchNormalization()</span><br><span class="line">    </span><br><span class="line">    self.conv3 = tf.keras.layers.Conv2DTranspose(<span class="number">1</span>, (<span class="number">5</span>, <span class="number">5</span>), strides=(<span class="number">2</span>, <span class="number">2</span>), padding=<span class="string">'same'</span>, use_bias=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, x, training=True)</span>:</span></span><br><span class="line">    <span class="comment"># input is a vector of shape [?, 100(noise_dim)] --&gt; [?, 7*7*64]</span></span><br><span class="line">    x = self.fc1(x)</span><br><span class="line">    x = self.batchnorm1(x, training=training)</span><br><span class="line">    x = tf.nn.relu(x)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># [?, 7*7*64] --&gt; [?, 7, 7, 64]</span></span><br><span class="line">    x = tf.reshape(x, shape=(<span class="number">-1</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">64</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># [?, 7, 7, 64] --&gt; [?, 7, 7, 64]</span></span><br><span class="line">    x = self.conv1(x)</span><br><span class="line">    x = self.batchnorm2(x, training=training)</span><br><span class="line">    x = tf.nn.relu(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># [?, 7, 7, 64] --&gt; [?, 14, 14, 32]</span></span><br><span class="line">    x = self.conv2(x)</span><br><span class="line">    x = self.batchnorm3(x, training=training)</span><br><span class="line">    x = tf.nn.relu(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># [?, 14, 14, 32] --&gt; [?, 28, 28, 1], output range (-1, 1)</span></span><br><span class="line">    x = tf.nn.tanh(self.conv3(x))  </span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Discriminator</span><span class="params">(tf.keras.Model)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">    super(Discriminator, self).__init__()</span><br><span class="line">    self.conv1 = tf.keras.layers.Conv2D(<span class="number">64</span>, (<span class="number">5</span>, <span class="number">5</span>), strides=(<span class="number">2</span>, <span class="number">2</span>), padding=<span class="string">'same'</span>)</span><br><span class="line">    self.conv2 = tf.keras.layers.Conv2D(<span class="number">128</span>, (<span class="number">5</span>, <span class="number">5</span>), strides=(<span class="number">2</span>, <span class="number">2</span>), padding=<span class="string">'same'</span>)</span><br><span class="line">    self.dropout = tf.keras.layers.Dropout(<span class="number">0.3</span>)</span><br><span class="line">    self.flatten = tf.keras.layers.Flatten()</span><br><span class="line">    self.fc1 = tf.keras.layers.Dense(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, x, training=True)</span>:</span></span><br><span class="line">    <span class="comment"># [?, 28, 28, 1] --&gt; [?, 14, 14, 64]</span></span><br><span class="line">    x = tf.nn.leaky_relu(self.conv1(x))</span><br><span class="line">    x = self.dropout(x, training=training)</span><br><span class="line">    <span class="comment"># [?, 14, 14, 64] --&gt; [?, 7, 7, 128]</span></span><br><span class="line">    x = tf.nn.leaky_relu(self.conv2(x))</span><br><span class="line">    x = self.dropout(x, training=training)</span><br><span class="line">    x = self.flatten(x)</span><br><span class="line">    x = self.fc1(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">generator = Generator()</span><br><span class="line">discriminator = Discriminator()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Defun gives 10 secs/epoch performance boost</span></span><br><span class="line"><span class="comment"># ç”¨æ¥æåˆ°è¿è¡Œé€Ÿåº¦ï¼Œpython function to calllable tf graph</span></span><br><span class="line">generator.call = tf.contrib.eager.defun(generator.call)</span><br><span class="line">discriminator.call = tf.contrib.eager.defun(discriminator.call)</span><br></pre></td></tr></table></figure>
<h2 id="Define-the-loss-functions-and-the-optimizer"><a href="#Define-the-loss-functions-and-the-optimizer" class="headerlink" title="Define the loss functions and the optimizer"></a>Define the loss functions and the optimizer</h2><ul>
<li><p><strong>Discriminator loss</strong> (è¿™é‡Œå…¶å®å°±æ˜¯classificationçš„lossï¼Œä½†åšäº†ç‚¹å˜åŒ–)</p>
<ul>
<li>The discriminator loss function takes 2 inputs; <strong>real images, generated images</strong></li>
<li>real_loss is a sigmoid cross entropy loss of the <strong>real images</strong> and an <strong>array of ones (since these are the real images)</strong></li>
<li>generated_loss is a sigmoid cross entropy loss of the <strong>generated images</strong> and an <strong>array of zeros (since these are the fake images)</strong></li>
<li>Then the total_loss is the sum of real_loss and the generated_loss</li>
</ul>
</li>
<li><p><strong>Generator loss</strong> (generatorçš„lossä¸discriminatorä¸­generated_image_lossç›¸å)</p>
<ul>
<li>It is a sigmoid cross entropy loss of the generated images and an <strong>array of ones</strong></li>
</ul>
</li>
</ul>
<ul>
<li>The discriminator and the generator optimizers are different since we will train them separately.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">discriminator_loss</span><span class="params">(real_output, generated_output)</span>:</span></span><br><span class="line">    <span class="comment"># [1,1,...,1] with real output since it is true and we want</span></span><br><span class="line">    <span class="comment"># our generated examples to look like it</span></span><br><span class="line">    real_loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=tf.ones_like(real_output), logits=real_output)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># [0,0,...,0] with generated images since they are fake</span></span><br><span class="line">    generated_loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=tf.zeros_like(generated_output), logits=generated_output)</span><br><span class="line"></span><br><span class="line">    total_loss = real_loss + generated_loss</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> total_loss</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generator_loss</span><span class="params">(generated_output)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.losses.sigmoid_cross_entropy(tf.ones_like(generated_output), generated_output)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">discriminator_optimizer = tf.train.AdamOptimizer(<span class="number">1e-4</span>)</span><br><span class="line">generator_optimizer = tf.train.AdamOptimizer(<span class="number">1e-4</span>)</span><br></pre></td></tr></table></figure>
<h2 id="Checkpoints-Object-based-saving"><a href="#Checkpoints-Object-based-saving" class="headerlink" title="Checkpoints (Object-based saving)"></a>Checkpoints (Object-based saving)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">checkpoint_dir = <span class="string">'./data/dcgan/training_checkpoints'</span></span><br><span class="line">checkpoint_prefix = os.path.join(checkpoint_dir, <span class="string">"ckpt"</span>)</span><br><span class="line">checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,</span><br><span class="line">                                 discriminator_optimizer=discriminator_optimizer,</span><br><span class="line">                                 generator=generator,</span><br><span class="line">                                 discriminator=discriminator)</span><br></pre></td></tr></table></figure>
<h2 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h2><ul>
<li>We start by iterating over the dataset</li>
<li>The generator is given <strong>noise as an input</strong> which when passed through the generator model will output a image looking like a handwritten digit</li>
<li>The discriminator is given the <strong>real MNIST images as well as the generated images (from the generator)</strong>.</li>
<li>Next, we calculate the generator and the discriminator loss.</li>
<li>Then, we calculate the gradients of loss with respect to both the generator and the discriminator variables (inputs) and apply those to the optimizer.</li>
</ul>
<h2 id="Generate-Images"><a href="#Generate-Images" class="headerlink" title="Generate Images"></a>Generate Images</h2><ul>
<li>After training, its time to generate some images!</li>
<li>We start by creating noise array as an input to the generator</li>
<li>The generator will then convert the noise into handwritten images.</li>
<li>Last step is to plot the predictions and <strong>voila!</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">EPOCHS = <span class="number">150</span></span><br><span class="line">noise_dim = <span class="number">100</span></span><br><span class="line">num_examples_to_generate = <span class="number">16</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># keeping the random vector constant for generation (prediction) so</span></span><br><span class="line"><span class="comment"># it will be easier to see the improvement of the gan.</span></span><br><span class="line"><span class="comment"># noise æ˜¯æ­£å¤ªåˆ†å¸ƒçš„100ç»´å™ªå£°</span></span><br><span class="line">random_vector_for_generation = tf.random_normal([num_examples_to_generate,</span><br><span class="line">                                                 noise_dim])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_and_save_images</span><span class="params">(model, epoch, test_input)</span>:</span></span><br><span class="line">  <span class="comment"># make sure the training parameter is set to False because we</span></span><br><span class="line">  <span class="comment"># don't want to train the batchnorm layer when doing inference.</span></span><br><span class="line">  predictions = model(test_input, training=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">  fig = plt.figure(figsize=(<span class="number">4</span>,<span class="number">4</span>))</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(predictions.shape[<span class="number">0</span>]):</span><br><span class="line">      plt.subplot(<span class="number">4</span>, <span class="number">4</span>, i+<span class="number">1</span>)</span><br><span class="line">      <span class="comment"># generated imageçš„shape [28,28,1], range æ˜¯(-1, 1)</span></span><br><span class="line">      plt.imshow(predictions[i, :, :, <span class="number">0</span>] * <span class="number">127.5</span> + <span class="number">127.5</span>, cmap=<span class="string">'gray'</span>)</span><br><span class="line">      plt.axis(<span class="string">'off'</span>)</span><br><span class="line">        </span><br><span class="line">  plt.savefig(<span class="string">'./data/dcgan/image_at_epoch_&#123;:04d&#125;.png'</span>.format(epoch))</span><br><span class="line">  plt.show()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(dataset, epochs, noise_dim)</span>:</span>  </span><br><span class="line">  <span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">    start = time.time()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># dataset æ˜¯ tf.data.Dataset, iterable</span></span><br><span class="line">    <span class="keyword">for</span> images <span class="keyword">in</span> dataset:</span><br><span class="line">      <span class="comment"># generating noise from a normal distribution</span></span><br><span class="line">      noise = tf.random_normal([BATCH_SIZE, noise_dim])</span><br><span class="line">      </span><br><span class="line">      <span class="comment"># gradientTapeæ˜¯eager executioné‡Œè‡ªåŠ¨ç®—gradientçš„</span></span><br><span class="line">      <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> gen_tape, tf.GradientTape() <span class="keyword">as</span> disc_tape:</span><br><span class="line">        <span class="comment"># é€šè¿‡noiseç”Ÿæˆçš„image</span></span><br><span class="line">        generated_images = generator(noise, training=<span class="keyword">True</span>)</span><br><span class="line">        <span class="comment"># ä»datasetä¸­çš„çœŸå®image å’Œ noiseç”Ÿæˆimageçš„sigmoid output</span></span><br><span class="line">        real_output = discriminator(images, training=<span class="keyword">True</span>)</span><br><span class="line">        generated_output = discriminator(generated_images, training=<span class="keyword">True</span>)</span><br><span class="line">        <span class="comment"># generator loss: generated imageè¢«åˆ†ç±»æˆ1åˆ™lossä¸º0</span></span><br><span class="line">        gen_loss = generator_loss(generated_output)</span><br><span class="line">        <span class="comment"># discriminator loss: generated imageè¢«åˆ†ç±»æˆ0åˆ™lossä¸º0ï¼Œreal imageè¢«åˆ†ç±»æˆ1åˆ™lossä¸º0</span></span><br><span class="line">        disc_loss = discriminator_loss(real_output, generated_output)</span><br><span class="line">        </span><br><span class="line">      gradients_of_generator = gen_tape.gradient(gen_loss, generator.variables)</span><br><span class="line">      gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.variables)</span><br><span class="line">      </span><br><span class="line">      <span class="comment"># æ³¨æ„ï¼šgeneratorå’Œdiscriminatoræ˜¯åˆ†å¼€trainçš„</span></span><br><span class="line">      generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.variables))</span><br><span class="line">      discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.variables))</span><br><span class="line"></span><br><span class="line">      </span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">1</span> == <span class="number">0</span>:</span><br><span class="line">      display.clear_output(wait=<span class="keyword">True</span>)</span><br><span class="line">      generate_and_save_images(generator,</span><br><span class="line">                               epoch + <span class="number">1</span>,</span><br><span class="line">                               random_vector_for_generation)  <span class="comment"># æµ‹è¯•ç”¨çš„noiseæ˜¯globalçš„</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># saving (checkpoint) the model every 15 epochs</span></span><br><span class="line">    <span class="keyword">if</span> (epoch + <span class="number">1</span>) % <span class="number">15</span> == <span class="number">0</span>:</span><br><span class="line">      checkpoint.save(file_prefix = checkpoint_prefix)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">print</span> (<span class="string">'Time taken for epoch &#123;&#125; is &#123;&#125; sec'</span>.format(epoch + <span class="number">1</span>,</span><br><span class="line">                                                      time.time()-start))</span><br><span class="line">  <span class="comment"># generating after the final epoch</span></span><br><span class="line">  display.clear_output(wait=<span class="keyword">True</span>)</span><br><span class="line">  generate_and_save_images(generator,</span><br><span class="line">                           epochs,</span><br><span class="line">                           random_vector_for_generation)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train(train_dataset, EPOCHS, noise_dim)</span><br></pre></td></tr></table></figure>
<p><img src="/images/dcgan/output_26_0.png" alt="png"></p>
<h2 id="Restore-the-latest-checkpoint"><a href="#Restore-the-latest-checkpoint" class="headerlink" title="Restore the latest checkpoint"></a>Restore the latest checkpoint</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># restoring the latest checkpoint in checkpoint_dir</span></span><br><span class="line">checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))</span><br></pre></td></tr></table></figure>
<pre><code>&lt;tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0x7f23695fb668&gt;
</code></pre><h2 id="Display-an-image-using-the-epoch-number"><a href="#Display-an-image-using-the-epoch-number" class="headerlink" title="Display an image using the epoch number"></a>Display an image using the epoch number</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">display_image</span><span class="params">(epoch_no)</span>:</span></span><br><span class="line">  <span class="keyword">return</span> PIL.Image.open(<span class="string">'./data/dcgan/image_at_epoch_&#123;:04d&#125;.png'</span>.format(epoch_no))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">display_image(EPOCHS)</span><br></pre></td></tr></table></figure>
<p><img src="/images/dcgan/output_31_0.png" alt="png"></p>
<h2 id="Generate-a-GIF-of-all-the-saved-images"><a href="#Generate-a-GIF-of-all-the-saved-images" class="headerlink" title="Generate a GIF of all the saved images."></a>Generate a GIF of all the saved images.</h2><!-- TODO(markdaoust): Remove the hack when Ipython version is updated -->
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> imageio.get_writer(<span class="string">'./data/dcgan/dcgan.gif'</span>, mode=<span class="string">'I'</span>) <span class="keyword">as</span> writer:</span><br><span class="line">  filenames = glob.glob(<span class="string">'./data/dcgan/image*.png'</span>)</span><br><span class="line">  filenames = sorted(filenames)</span><br><span class="line">  last = <span class="number">-1</span></span><br><span class="line">  <span class="keyword">for</span> i,filename <span class="keyword">in</span> enumerate(filenames):</span><br><span class="line">    frame = <span class="number">2</span>*(i**<span class="number">0.5</span>)</span><br><span class="line">    <span class="keyword">if</span> round(frame) &gt; round(last):</span><br><span class="line">      last = frame</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      <span class="keyword">continue</span></span><br><span class="line">    image = imageio.imread(filename)</span><br><span class="line">    writer.append_data(image)</span><br><span class="line">  image = imageio.imread(filename)</span><br><span class="line">  writer.append_data(image)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># this is a hack to display the gif inside the notebook</span></span><br><span class="line">os.system(<span class="string">'cp ./data/dcgan/dcgan.gif ./data/dcgan/dcgan.gif.png'</span>)</span><br></pre></td></tr></table></figure>
<pre><code>0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">display.Image(filename=<span class="string">"./data/dcgan/dcgan.gif.png"</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/images/dcgan/output_35_0.png" alt="png"></p>
<p>To downlod the animation from Colab uncomment the code below:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#from google.colab import files</span></span><br><span class="line"><span class="comment">#files.download('dcgan.gif')</span></span><br></pre></td></tr></table></figure>
</section>
    <!-- Tags START -->
    
      <div class="tags">
        <span>Tags:</span>
        
  <a href="/tags#GAN">
    <span class="tag-code">GAN</span>
  </a>

  <a href="/tags#CNN">
    <span class="tag-code">CNN</span>
  </a>

      </div>
    
    <!-- Tags END -->
    <!-- NAV START -->
    
  <div class="nav-container">
    <!-- reverse left and right to put prev and next in a more logic postition -->
    
      <a class="nav-left" href="/2019/01/06/neural-style-trans/">
        <span class="nav-arrow">â† </span>
        
          neural-style-trans
        
      </a>
    
    
  </div>

    <!-- NAV END -->
    
      <!-- Gitment START -->
      <div id="comments"></div>
      <!-- Gitment END -->
    
  </article>
  <!-- Article END -->
  <!-- Catalog START -->
  
    <aside class="catalog-container">
  <div class="toc-main">
    <strong class="toc-title">Catalog</strong>
    
      <ol class="toc-nav"><li class="toc-nav-item toc-nav-level-5"><a class="toc-nav-link" href="#Copyright-2018-The-TensorFlow-Authors"><span class="toc-nav-text">Copyright 2018 The TensorFlow Authors.</span></a></li></ol><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#DCGAN-An-example-with-tf-keras-and-eager"><span class="toc-nav-text">DCGAN: An example with tf.keras and eager</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#Import-TensorFlow-and-enable-eager-execution"><span class="toc-nav-text">Import TensorFlow and enable eager execution</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#Load-the-dataset"><span class="toc-nav-text">Load the dataset</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#Use-tf-data-to-create-batches-and-shuffle-the-dataset"><span class="toc-nav-text">Use tf.data to create batches and shuffle the dataset</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#Write-the-generator-and-discriminator-models"><span class="toc-nav-text">Write the generator and discriminator models</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#Define-the-loss-functions-and-the-optimizer"><span class="toc-nav-text">Define the loss functions and the optimizer</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#Checkpoints-Object-based-saving"><span class="toc-nav-text">Checkpoints (Object-based saving)</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#Training"><span class="toc-nav-text">Training</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#Generate-Images"><span class="toc-nav-text">Generate Images</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#Restore-the-latest-checkpoint"><span class="toc-nav-text">Restore the latest checkpoint</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#Display-an-image-using-the-epoch-number"><span class="toc-nav-text">Display an image using the epoch number</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#Generate-a-GIF-of-all-the-saved-images"><span class="toc-nav-text">Generate a GIF of all the saved images.</span></a>
    
  </li></ol></li></div>
</aside>
  
  <!-- Catalog END -->
</main>

<script>
  (function () {
    var url = 'http://yoursite.com/2019/01/06/dcgan/';
    var banner = ''
    if (banner !== '' && banner !== 'undefined' && banner !== 'null') {
      $('#article-banner').css({
        'background-image': 'url(' + banner + ')'
      })
    } else {
      $('#article-banner').geopattern(url)
    }
    $('.header').removeClass('fixed-header')

     // error image
    $(".markdown-content img").on('error', function() {
      $(this).attr('src', 'http://file.muyutech.com/error-img.png')
      $(this).css({
        'cursor': 'default'
      })
    })

    // zoom image
    $(".markdown-content img").on('click', function() {
      var src = $(this).attr('src')
      if (src !== 'http://file.muyutech.com/error-img.png') {
        var imageW = $(this).width()
        var imageH = $(this).height()
        
        var zoom = ($(window).width() * 0.95 / imageW).toFixed(2)
        zoom = zoom < 1 ? 1 : zoom
        zoom = zoom > 2 ? 2 : zoom
        var transY = (($(window).height() - imageH) / 2).toFixed(2)

        $('body').append('<div class="image-view-wrap"><div class="image-view-inner"><img src="'+ src +'" /></div></div>')
        $('.image-view-wrap').addClass('wrap-active')
        $('.image-view-wrap img').css({
          'width': `${imageW}`,
          'transform': `translate3d(0, ${transY}px, 0) scale3d(${zoom}, ${zoom}, 1)`
        })
        $('html').css('overflow', 'hidden')

        $('.image-view-wrap').on('click', function() {
          $(this).remove()
          $('html').attr('style', '')
        })
      }
    })

    // qrcode
    var qr = new QRious({
      element: document.getElementById('share-qrcode'),
      value: document.location.href
    });

    // gitment
    var gitmentConfig = "dongnanzhy";
    if (gitmentConfig !== 'undefined') {
      var gitment = new Gitment({
        id: "dcgan",
        owner: "dongnanzhy",
        repo: "dongnanzhy.github.io",
        oauth: {
          client_id: "6e8efba4b92de298d180",
          client_secret: "ef25328fb6ac8348ad6921d892776be451db3639"
        },
        theme: {
          render(state, instance) {
            const container = document.createElement('div')
            container.lang = "en-US"
            container.className = 'gitment-container gitment-root-container'
            container.appendChild(instance.renderHeader(state, instance))
            container.appendChild(instance.renderEditor(state, instance))
            container.appendChild(instance.renderComments(state, instance))
            container.appendChild(instance.renderFooter(state, instance))
            return container;
          }
        }
      })
      gitment.render(document.getElementById('comments'))
    }
  })();
</script>

<script>
  var disqus_shortname = '';
  
  var disqus_url = 'http://yoursite.com/2019/01/06/dcgan/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//go.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>

    <div class="scroll-top">
  <span class="arrow-icon"></span>
</div>
    <footer class="app-footer">
  <p class="copyright">
    &copy; 2019 | Powered by <a href="https://hexo.io" target="_blank">Hexo</a>
  </p>
</footer>

<script>
  function async(u, c) {
    var d = document, t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
    o.src = u;
    if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
    s.parentNode.insertBefore(o, s);
  }
</script>
<script>
  async("//cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js", function(){
    FastClick.attach(document.body);
  })
</script>

<script>
  var hasLine = 'true';
  async("//cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js", function(){
    $('figure pre').each(function(i, block) {
      var figure = $(this).parents('figure');
      if (hasLine === 'false') {
        figure.find('.gutter').hide();
      }
      var lang = figure.attr('class').split(' ')[1] || 'code';
      var codeHtml = $(this).html();
      var codeTag = document.createElement('code');
      codeTag.className = lang;
      codeTag.innerHTML = codeHtml;
      $(this).attr('class', '').empty().html(codeTag);
      figure.attr('data-lang', lang.toUpperCase());
      hljs.highlightBlock(block);
    });
  })
</script>
<!-- Baidu Tongji -->

<script src="/js/script.js"></script>
  </body>
</html>